Hocamız Hakan UYGUN ; Mikroservisler ile Devops Notları ; Mustafa Akgül Özgür Yazılım 2025 Kış Kampı Eskişehir ; Meryem GELEN ;
//10.02.2025 Pazartesi
neden rancher değil de openshift? Satın alınmış ben de kullanacağım tamam haklı bir gerekçe
Uygulama yapmayacağız Temel Mimarı Anlatacağım
Gerçekten mikroservis kullanmalı mısınız?
Özgür Yazılım Nedir?
Sahipsiz Lisanssız değildir Açık Kaynak kodludur. İnceleyebilir okuyabilir değiştirebilir dağıtabilirsiniz.
genel kamu lisansı ile değişiklik yaptıysanız siz de o lisans ile vermelisiniz.
public lisans gibi lisanslarda mozilla public lisansta referans vermen lazım ibaresi vardır. 
creative commons lisansları var CC BY Atıf (Attribution) iconlar fontlar fotoğraflar bazı js kütüphaneleri
bunlar içerik lisansları by cc bunların ne olduğuna bakmalı lisans ihlali yapmamalısınız.
benim adımı geçirmelisiniz tarzında noncomercial ibaresi varsa ücretli bişey yapacaksanız onu kullanamaz satamazsınız
kod geliştirirken internetten bulduğunuz bişeyi pata küte kodunuza gömemezsiniz arkadaşlar
o lisansa telife uymalısınız
copilot tarzı kod üretme yapay zeka papağan kodu nereden getirdiğine dair geliştiricileri de bilmiyor bu sebeple davalar başladı
size getirdiği kod gpl kodu olabilir.
turktelekom önceden ses çevirmede ffl li bir kod kullanmış , Federal Firearms License, gelitiricileri yakalandılar ve gpli sunmak zorunda kaldılar içinde parola varmış
borland delphi flash geliştiricilere yazık oldu bir gecede aldıkları karar çok kişiyi etkiledi
microsoft 3 yıl boyunca uğraştılar typescript ile devam et, M'yi boşver dediler ve bir günde M ekibi dağıtıldı 3 yıl boyunca olan emek boşa gitti. 
yani diyeceğim o ki yöneleceğiniz alanı ona göre seçin.
google her yıl ürün öldürür 3 yıla anguların ipi çekilebilir. react'ın arkasında da facebook var. 
tecrübe yenilen kazıkların bileşkesi sonuçta.
GPL general public lisansı 
-suriyeliler kullanamaz maddesini araştır. lisansın sonundaki cümle 

Mikroservisler nedir, gerçekten kullanmak gerekli mi. 
modüler yapılar kendi başına çalışabilen atomik servisler hazırlanmasıdır tam tanımı da yok.

Servis nedir?
------------
SoA
RPC/RMI/IPC
Web Service
SOAP
Rest

Yaklaşık on yılda bir atomu yeniden keşfediyoruz.
ilk yazılan servisler main frame.lerdi ve birbiri ile konuşması için rpc protokolleri vardı
binary network tanımlanmıştı (IIOP)
Java ilk akıllı ev tost makinesi buzdolabı çalıştırmak için geliştirildi.
x86 ve arm serisi CPU mimarisi kaldı şimdilerde o yıllarda onlarca vardı
MAC den windowsa veri transferi edemiyorduk çünkü disk yapısı vardı
RMI remote method inlocation diye bir şey geliştirdi Sun Microsystems javada sonra web servis çılgınlığı başladı
binary protocoller ile iş yapmak zordu http üzerinden kolay oldu render etmek yerine herkes servis apisini yazıp veri transfer etmek istedi.

bu da sıkıntı yarattı.
a firması a api seti b firması b api seti yazınca buna simple object protokol standandartı getirildi SOAP
Servis Orianted Architecture diye bir isim getirildi SoA ürünleri var becerileri SOAP web servis yazıyorsunuz SoA ürünü bu web servisi ayakta tutmak vs için çeşitli araç gereçler sağlıyor

Ya biz niye bu kadar XML ile uğraşıyoruz ki httpnin get put post komutları var zaten CRUD için buunu kullanalım json formatında iletelim dedi bir yazılımcı
XML adı kötüye çıktı çünkü kullandıkları SoA ürünü kötü XML'in adı kötüye çıktı
XML sayesinde html var bir araba şeyi bu sayede yapabiliyoruz XML kötü değil ama adı kötüye çıkınca rest geldi
url get istedği atıyorum json veriyorum siliyorum güncelliyorum pat pat kolayca amaaa sonra json sürümünü nasıl takip edicem
validation nasıl yapacağım
json schema geldi bir başka dosya formatı, xml olma yolunda koşuyor
jsonschema org olması lazım orda standart tanımlıyorlar
yaml yet another markup language geldi kendini json subseti olarak tanımlamaya başladı 
grpc  (Google Remote Procedure Call) rpci  ben bu kadar çok serviste network trafiği oluşuyor bende,  ben bunları json dolaştırmam zor binary yapayım dedi
apache da benzeri apache avro tanımladı, Avro, Apache'nin Hadoop projesi kapsamında geliştirilen satır odaklı bir uzaktan prosedür çağrısı ve veri serileştirme çerçevesidir. 
arada action commanda göndermek gerekiyor hepsini json yapmak yetmiyor
remote procedure call ile daha kolay oldu ? RPC

büyük şirketlerin neyi neden kullandığı sizin için önemli olmamalı
redis facebook günlük request sayısı sizinki ile karşılaştırılabilir mi
mongo küçük verilerle çalışmak için arayanlar oldu.
1PB 2 PB petabyte verimiz var dediler, 1 mi 2 mi arada dağlar 1024 TB kadar fark var
ama mimariyi seçerken böyle seçilmez
kalite maliyet zaman üçgenindeki iki şeyi optimize edebilirsiniz
maliyeti az olsun zaman az olsun derseniz kaliteden ödün vermelisiniz
hem maliyeti az olsun hem kaliteli olsun derseniz uzun zaman alacak
iyi analiz edip neye ihtiyacınız olduğuna karar vermelisiniz
makinenin skasi kartının pili bitmiş, SCSI(Small Computer System Interface),durmuş,  dışarıdan istek almayı kesmiş, veri almayı durdurmuş, veri kaybı yok backupdan dönüldü, ve cash yapamıyor makine veri tabanı sistemi durmuş terminal açılmıyor, 8 saat sürdü çok dediler,
cpu sökmüşler felaket kurtarmadan lisans maliyeti düşürmek için database'in ne olduğunu anladık, maliyeti çok gelince haa o zaman 24 saat sürebilir dediler.
/////

intelliJ kotlin
redhat ceylonn diye bir dil ceylon apache'e bağışladı orjinal geliştiricisi dahi bıraktı 
ilgi community desteği çekince bitiyor
doğal süreç her şeyin bir ömrü var

Rest ile servis yazınca bu mimari backend sunucu tarafında tanımlanıyor
bütün frontend tarafındaki apiler zor deyince graphql?  yazılıyor bu iş frontende bırakılıyor
önceden client db graphql ile storedprocedure ile middleware implement ediyorsunuz şuandaki tüm telefon uygulamalarınız birer masaüstü uygulmasına dönüyor
bankalar cobol ve plone kullanıyor hala göç maliyeti yüksek geliyor mainframelerin maliyeti yüksek çünkü dikey büyüyor
biz masaüstü yazalım dediler client server mimarisi geldi
bankadaki 10binlerce pc donanım seviyesindeki bakımı ciddi maliyet
bakımı olabildiğince bakımı az sistemler koyalım bakımı merkezi sunucuda yapalım
html böyle doğdu.
istemcide sadece browser olması yeterli
program kurmam merkezi sunucuyu ölçekler yönetirim düşüncesiyle
sonra cep telefonları geldi
cep telefonda web uygulaması yerine framework ile native mobil masaüstü uygulması yazalım
webview yapıyor gerçekten native değil artık
güncelleme yapmak istediğinizde bir haftaya yakın güncelleme ile uğraşılıyor telefon uygulaması o yüzden artık aynı sorunlara benzer çözümler olduğu için masaüstüne dönecek


bir servisin karşılaması gereken yük çok daha hızlı gelişiyor
html http
akademik makale paylaşmaya çalışıyorlar
earn üzerinde birbirlerine akademik makale atacaklar
html bir dil yazalım tarayıcı göstersin a href link var başka makaleyi gösteriyor
ve bir protocol yazalım http yazıldı böyle başladı
biraz da read only yerine bilgi girelim dediler html formlar başladı
sonra tarayıcı kavgaları başladı
netscape ve internet explorer arasında kavga başladı w3c consortium dinlemedi kafalarına göre taglar oluşturdu. netscape batttı yerine mozilla firefox kuruldu.
internetexplorer yerine chrome sonra safari 
google chrome, fena değilmiş dedi safarinin kullandığı temelindeki kht kodunu kullandı ve geliştridi  

nasa new horizon pluton fotoları için 5 yıl + 20 yıl + 5 yıl sürüyor ekip hep aynı yerde
Türkiyede 2 yıldan fazla sürmesi problem 

Mikroservis kullanmalı mısınız?

sırf trend ve netflix kullanıyor diye kullanmayın
çok ciddi operasyonel yük getirir
uygulamanızda ölçekleme problemi yoksa bulaşmayın

düzenli sürüm çıkartma ve deployment politikanız yoksa kullanmayın
bağımlılık dependency karışık

netflixin spring clouda bakın servisleri sadece ayakta tutmak için yazdıkları kodun haddi hesabı yok

caus monkey var netflixte rastgele bir servisi kapatır.
herhangi bir servisin düşmesi sorun yaratmamalı diyor ve rastgele kapatıyor
pod kapatıyor ya da network kesiyor servis kapatıyor port kapatıyor random etkilenmesin diye

iyi yapmazsanız gereksiz yere geçerseniz 1 monolith yerine 5 monolith oluyor

farklı departmanlarda gerçekten bağımsız ekiplerin geliştirdiği ürünler için
farklı diller py java vs kullanılıyor diyelim o zaman mikroservis çok anlamlı

ürünlerin farklı parçaları kendi hayat döngüsüne sahip olması
mesela ERP var kocaman diyelim
farklı modüller var ERP oluşturan 
stok yönetiminde nadiren değişiklik oluyor
monolith yapınca herşeyi güncellemelisiniz burda servis bazlı yapacaksınız
ödemeyi içine gömmek yerine servis olarak yazmalısıınz
sürekli bir apı değişikliği gerektirebilir bankalarda

bankaların bazı parçalarını isteseniz de mikroservis yazamazsınız transaction gerekiyor dolayısıyla hybrit olmalı

mikroserviste yük dengeleme sadece bir servis yük yiyor yatay ölçekleme ile yaparsanız neyin ölçeklenmesi gerekiyorsa onu ölçeklersiniz

makroservis de var monolithten farklı olarak bir ya da iki işi servis olarak verir bu yüzden mikroservis şart değil

uzun vadeli farklı göç olanakları sağlar

AB testi
kullanıcıların bir miktarına yeni yazılmış servis kullandırıyorum ona göre karar verebilirim  mikroserviste bunu yapmak mümkün

mikroservis tasarım desenleri kurallarına göre yazıyorsunuz, monolithte böyle değil

Her mikroservis;
kendi içinde bağımsız olmalı, bunun için bir tane daha servis olması gerek vs böyle olmaz,
hayır. kendi içinde atomik olmalı.
diğer ilişkili olduğu diğer servislerle API kontratları ile anlaşmalı
bağımlılık tanımlarken sitenin sepetini yaptım diyelim mikroservice yazdım
stok servisi ile konuşabilmeli
ödeme sistemine haber verme kısmına gideceğim konuşmam gereken başka servisler var
stok servisinin bana api sağlaması gerekiyor
ekipler contracts üzerinde baştan anlaşır
bu yüzden otomatik entegrasyon testlerine ihtiyacınız var, kontractı yanlış anlayığ yanlış implementasyon yaptıysanız misal

product jre yeter
geliştirme ortamına jdk jre gerek
ikisi sdk

iot internet of things o işe özel binary protocoller hazırlanabiliyor
kocaman json göndermek yerine byte gönderecek sıcaklık azaldı ise bir gönderecek tamam

Türkiyedeki tüm yazarkasalardan kocaman data almak yerine binary alacak bitti

klasik rest; conract openAPI swagger eski adı, temel hikaye şu, bu bir format 
get dersin şunu veririm
post dersin json cevap veririm
bu dokumanı yazarak openapı contracktını yazarım ve el sıkışırım
bu tasarım için araçlar da var
elinizde böyle bir servis varmış gibi oluyor

per database per service her mikroservice kendi databasei ile haberleşmeli
sipariş servisinin db.sinde cari servisin bilmemne bilgisini tutmamalıyım
çünkü caride değişiklik yapınca sipariş servisinin patlamayacağının garantisini vermez ama yine de sıkı bağlı mikroservisiniz olur bu da kabul edilebilir gerekçeniz varsa
zayıf bağlı olsun istemedik dersiniz ama zorunda tasarımınıza zorunlu kalıyorsunuz, 
mutlaka veritabanı değişiklik yönetimi ile beraber bunları yapmalısınız
 
ortak database antipattern servisin bağımsız olmasını engeller

s1 + db1
s2 + db2
s3 + db3

s1 s2'ye bağımlı olabilir ama gidip de db2 ye bağımlı olamaz

IDM ıdentitiy management monolith de yazıyor olsanız kullanıcı yönetimini ayrı yazmalısınız

kullanılan en kesitrme çözüm LDAP directory access protocoll aktive directory openLDAP apache vs birsürü var LDAP, http gibi bir protokel, ilk yazılma amacı telefon defteri yönnetmekti şimdi kullanıcı yönetiminde kullanılıyor
artık kullanıcı parolalası yetmiyor yetki vs de gerek

macrofronted ile yazdığım uygulamaları küçük küçük paketledik.

single sign on SSO biyerden login oldum bana bir daha kullanıcı adı sorma ya

OAuth JWT en yaygın kullanılanı

tekerleği yeniden keşfetmeyin IDM ürünü var JBOSS var, SSO desteği sunuyor
bu token içinde jwt esnek ama en az olmalı kullanıcı adı olmalı
jwt içini doldurmayın esnek diye çünkü her requestte bu dolaşacak

(stackness servis yazabilmek için?)
iki temel sorun yük dengeleme ve yüksek erişilebilirlik
yüksek erişilebilirlik, ne kadar süre kapalı kalabilir, kurumsal uygulamalr gece kapalı kalsa da olur ancak sağlık finansal vs açık kalmalı yüksek erişilebilir olması için ondan repica almalısınız.

free otp var sms desteği için ama dünyada sms kullanan tek ülkeyiz doğrulama için:D

key cloud başarılı inceleyin?  , oAuth için de geçerli signout olduğunda token akışı açısından access token süresi var refresh token ile 5 dk bitince yeniden alman lazım.

oAuthdan eski SAML var bir de sunucu taraflı OAuth client dağıtıyor
authentication authorization
authz authc kısaltması
kimlik doğrulama bu adam bu mu
yetkilendirme kısmı var 
rolebase access control yaptınız önden tanımlayarak

jwt içine rolleri de göüyor yetkilendirmeyi de oauth ile yapıyorsunuz

kullanıcı hangi yetkilere sahip olduğunu tutmak için ek tabla tutmanız gerekir ıdm üründe

-- öğleden sonra

Mikroservislerde transaction yönetmek zor
böyle bir sisteminiz varsa mikroservis kullanmaya kesin karar vermeniz lazım
transaction yönetimini genelde kütüphaneler destekliyor birinde hata varsa transaction rollback yapıyor geri alıyor
birden fazla servise gidiyorsa orneğin dosya yükleme transaction ya yok ya da zor
servis tabanlı mimarilerde örneğin ödeme sistemleri e ticaret banka ile anlaşmışım ödemeyi aldı mı almadı mı
kullanıcı bilgilerini aldım db.ye yazdım bankaya gittim banka böyle bir kullanıcı yok dedi geri almam lazım
1-3 dk arasında transactionı açık tutup db.yi de block edemem
biz bunu farklı yapacağız
geriye dönüp haydi az önce yaptıklarını geri al demem lazım
işlemin yapılıp yapılmadığını anlamak için durum kısmına ihtiyacım var
muhasebe yazılımlarında yapılan işlem silinmez ters kayıt yapılır
ek flagler tutulur kayıtın son halimi mi değil mi
gerçekten silmeyiz soft delete yaparız
silindi diye işaretlenen kayıtları house cleaning yaparak çöp toplayarak gerçekten silme yapılacaksa yapılır
çoğu yerde gerçekten silinmez arşive alınır
o yüzden bu bir sistem tasarımı değil mikroservis yazılımı ile yazılım geliştirmelisiniz ki başarılı bir şekilde mikroservis mimarisini uygulayabilin
JTA java transaction api var javada
two face commit diye bir yapı var yaklaşık 40 yıldır
önce 1. transaction yapıp 2. sefer üzerinden geçip gerçekten commit mi yapacaksınız kararı verilir
saga patterni örneği var mikroserviste transaction problemini çözmek için uygulanan yöntem
bunu baştan planlamalısınız.

asenkronda hiç haber almayabiliriz işin içine timeout giriyor bu yüzden
sorun network problemi de olabilir
transaction garantisi veren mq veren bir şey kullanacaksınız ya da asenkron transactiion yapmayacaksınız

bilet alırken belirlenen süre içinde koltuk rezerve ediliyor alamazsanız geri açılmalı koltuk. 

fener galatsaray bileti satılacak biletix 10 kişi alıp geri kalanı binlercesi bekleme odasında firewall önünde redirect ediyorsun

pattern nedir? tasarım deseni bu bir mimarlık terimi
yazılım mühendisliği diye bir dal henüz yok
bir tane ölçülebilir mühendislik çalışması var o da net değil, bizimkisi zanaat
3 gün de olur 1 ay da olur kestiremiyoruz
önce tüm isterler çıkarılır vs vs yazılımda mümkün değil

1 projede çalıştım 3 kere müdür 2 kere kanun değişti bir yılda iki üç kere yeniden başladık projeye

algoritma tek başına yetmiyor 
gang4 ekibi 40 tasarım deseni üretiyorlar singleton bir tane instance oluşturacak
factory pattern
builder pattern
antipattern abi bunları yapma tarzında yazılıyor
en yaygın kullanılan 7-8 tanesi
bunlar yönergeler çözüm yolları
implementasyonları farklı farklı olabilir size kalmış

algoritmalar ve tasarım patternlerini mutlakaya okuyunuz.
aklınıza gelmeyen bir problem ve çözümü var kullandıklarınız da vardır

mikroservis yapıp saga patterni duymayan var
oyundaki bir araba yükü dağıtmak için istatistik bilgisi toplamak için çıktı ilk başta saga patterni.

mikroservice yarattığı sorunlar;
operasyonel yük
problem tespiti zor
sla service layer agreement canlı sistemin ne kdar ayakta kalabilir?
düzgün sürüm politikası şart, 
servislerimiz diğerinin apisine bağlı bu yüzden bir uygulama sürümü iki api sürümü yapılmalı
apı abi var application binary interface ? 
abi kırmak ?
implementasyon kırmak ? apide değişiklik yok sonuçlar farklı bağımlılığı yönetmeye ihtiyacınız var dependency matrix tutmanız gerekiyor
SemVer semantic versioninng şiddetle bunu kullanmanızı tavsiye ederim sürüm numaralandırma için 
1-0-2 major minor bugfix.
major 1 den 2'ye değişince major değişikliktir göç planlamayı gerektirir kullanıcı arayüzü değişti. minor numara değişmişse yeni bir özellik eklenmiştir yeni bir ayar gelmiştir. bugfix değişmişse gözü kapalı değiştirmeniz gerekiyor sadece hata değişmiştir.
bu değişiklikleri dikkatli yapmalısın
cuma akşam canlıya birşey konmaz
sürüm politikanız olmalı bir belgede
release stream java 6 ayda bir sürüm çıkarır
proje takvimi içinde product ownerın tercihleri ile belirlenir ne zaman olacağı
hata düzeltmeleri 
eğer sistem durmuşsa anında
zorlaştırıyorsa bir haftadır
formun şurasında hata varsa bir ayda

cı/cd 
bazen geliştirici paketler sürüme kadar çıkar

ek araç gereçler kullanmak şart

SDLC software development life cycle
git 
sürüm takip sistemi
iş takip sistemi
düzenli derleme sistemi cı sıfırdan derleme
static code analizi kod yazım kurallarını belirlemeli ve uymalısınız sonar
otomatik birim testleri fonskiyon testleri
code reviewlar

bunları uygulamadan mikroservise geçmemelisiniz

-----------------------------------------------------
mola sonrası

kötü olduğu için değil bunları bilerek başlamalısınız

bunları çözmek için yeni araç gereçe ihtiyacınız var
monitörüng araçlara vs
servis sayısı çok olduğu için beş makine değil 25 makine dolaşamazsınız
ops ekibi OS nin memory cpu vs izliyorlar normalde ama servisleri izleme becerisi olan bir araça geçmelisiniz
developer için merkezi log toplama sistemi ile toplanan loga bakacak ve hata tespiti için en az üç tane servise ihtiyacınız var
merkezi log servisi eleasticksearch 
bu loglara trace id konmalı işlem id.si de loglara yazılmalı ki bir araya toplanıp işlenebilsin
open tracing denen zımmırtıda hangi serviste neyin ne kadar zaman alıdığına ihtiyacınız var, fonskiyon seviyesine kadar metric toplamaya ihtiyacınız var
prometheus grafana vs gbi araçlara koyun kullanın

bunları kullanmıyorsanız mikroservislerle başedemezsiniz.

kaynak türketimi küçük sistemler için fazla
sistem büyüdükçe kaynak tüketimi maliyeti azalıyor

Sanallaştırma Yöntemleri
------------
sanal makine
konteyner
sanal ağ
sanal disk

baremetal üzerinde ölçekleme yaptıysanız 
düz pc üzerinde kurulan sadece db sunucuları kaldı arkadaşlar
diğerleri hep sanal üzerinde artık

ansible ?

konteynerda

app	/ app
Vos	/ Vos
Host os / Host os
şeklinde sanal makineniz host os üzerinde çalışırken 
konteyner direkt host os üzerinde çalışır.

teampadler linux çalıştırmak için çok iyi, opensuse paket yönetiminde de iyidir.
geliştiriciler oyun notebooklarından uzak durun derim

dockerengine ile containerd engineleri var containerd kullanmayı tercih ediyorum.

iş sadece makineyi sanallaştırmak yetmiyor ağı da sanallaştıracağız
örneğin dockerdaki tüm containerlar ayrı bir ip ile iç network ile konuşmaya başlar

wlan llan loopback ve üzerine sanal makine engine ayağa kaldırınca içinde apayrı bir network daha var

192.168. . . yerel ağ ip blocku
dolayısıyla size 255.255... kaldı

sanal ağlar nereden problem yaratıyor geliştiricilere
ipler bağlı olduğu routing tsblosu ve firewall vardır prodcutionda çalışmazsa ipler arasında routing açık değildir, binding yapılmamıştır, firewall portu kapamıştır yani bir parça da network ihtiyacınız var

servisleri doğrudan doğruya ip ile tanımlamayın domain name olsun
etc dosyasına yazın domain name.ler üzerinden koşun ve adam gibi isim verin s001 ismi ip.den daha okunaklı değil :D

bir de disk sanallaştırma kısmı var
rate 0 2 disk 
rate10 6 disk 300gblık 6 disk takmam lazım ki ..
dolayısıyla LVM logical volume management os.ye şu kdar disk ekle mount et lvm e diyoruz ki genişle hala yerel işletim sisteminden bahsediyorum
donanımların kaç tane dsk yönetecek slotu olabilir
NAS/SAN network area storage bu pcler size sadece disk alanı sağlıyor
amazon s3 blob storage device  

Kubernetes (k8s)

konteyner vs pod
kubernetes YAML dosyaları
configuration as code
Knative
kubernetes dağıtımları rancher openshift k3s vb

docker compose birden fazla image 
docker swarm çıktı sonradan 
konteynerları yönetmek için birşey yazalım dedi google kubernetesi başlattı ama şimdi en çok kubernetes için kod yazan red hat.
google, google cloud için lazım olan kadarını yazdı
red hat rancher ile sürekli geliştirmeye devam ediyor

vanilla kubernetes var direkt kendiniz kuruyorsunuz, mümkünse kullanmayın
gereken bilgi beceri emek çok fazla

okd özgğr yazılım versiyonu üründen geriden geliyor openshift çok pahalı
rancher opensuse destekliyor tavsiye edierm
k3s rancherın dağıtımı
ubuntunun mikrok8s var
terraform ve ansible ile bu işi yapmanızı öneririm
konteyner tarafında sadece uygulamayı paketlediğiniz docker podman containerd üzerinde yaparken servisler çoğalınca autoscaling vs yapmak gerektiğinde artık kubernetes

po, deplotyment description servise descriptionlarla karşılacaksınız artık
container eşiittir pod değildir pod sanal makine gibi düşünün içinde birden fazla contaier koşabilir
podman kullanılıyor bir pod içinde birden fazla image çalıştırılabiliyor

configuration as code herşey gitte durmalı hepsi configmapler properties dosyalarınız vs
KNative servis doğrudan doğruya kubernetes apisini kullanıyor demek
leader election zookeeper kullanmıyor da knative kullanıyor

CRD custom resource definition 
jenkinsin yaptığı işi kuberneteste yapan tekton var
sen bu crd yükle ben ordan yapıcam diyor knative oluyor

apigateway var knative'im ben diyor kubernetes custom resource olarak yazıyorsunuz ordan okuyor
etcd dağıtık veritabanı veri kaybetmediğini iddia ediyor openshift bir ara baya veri kaybetti ama

netflix hepsinde ortak network yapacak bişeye ihtiyaç duydu ve bir apigateway yazdılar, adı ?

kubernetes kümeleme, yarın anlatacağım

pod içinde kendi imageım haricinde startup imageı olacak misal bir for döngüsü backend hazır olana kadar kalkma
böylece birbirine bağlı servislerin birbirini beklemesini sağlıyorsunuz
bu beklemenin diğer nedeni de lider henüz seçilmedi onu bekle demek için de yapabilirsiniz

//11.02.2025 Salı
Sistem Mimarisinin Yazılım Üzerine Etkisi

Sizin monolithiniz bu kurallara göre yazıldıysa sizin mikroservis yapmanız kolay. Yazılım bunları sağlamıyorsa sistem yöneticisinin sonradan bunu yapması zor.

Bir cluster / küme oluşturmanız iki nedeni var
1 ) yüksek erişilebilirlik high availability
// kesinti olmasın
app ya da db çökebilir buna önlem almak için yanına bir tane daha koyarım aynısından ve bir de load balancer koyarım
load balancer gelen istekleri bunlara dağıtır
dbleri çoklamak biraz sıkıntı
sql postgre vs ilişkisel db sunucuları transactional kısmı için dikine büyümek ihtiyacında yüksek erişilebilir olsun istiyorsam buradaki her şeyin load balancer dahil herşeyin iki tane olması gerekiyr
fiziki sunucularımın dahi iki tane olması gerekiyor dün anlattım ya pili bitmiş 
bir ikili yaptığımız çoklamaya aktif pasif deniyor
yüksek erişilebilirlikte hepsinin aktif çalıması gerekmiyor birinin yedekte pasif beklemesi de olur 
replica tanımlanır birisi aktif db diğeri pasif db
main ya da primary diyoruz
primary db.ye tüm sorgularınız alırsınız başına bir iş gelirse diğerini devreye alırsınız

LB      LB
APP		APP + 1 + 2 
aktif	aktif
DB		DB
aktif	pasif

çökme gerekçesi diskte mi hata oldu donanım hatası mı os seviyesinde mi önce onu bulmalı
patroni diye servis kuruyorsunuz postgresql.de bu çökeni belirliyor ona göre diğerini ayağa kaldırıyor vs 
patroni de çökerse ?

kümenin dışında bir başka fiziki alana o datayı klasik backup almanız lazım.

iki APP arasında veri paylaşmanın olması session bilginizin iki node arasında haberleşmesi gerekiyor
HTTP
AppCode
DBCache

frameworklar jpa, redis vs bu işi sağlayacak bir cache sistemine ihtiyacınız var

mapping yöntemi java için map
diğer node'un da bunlardan haberi olması lazım
bir api tanımlıyoruz bunun için springcache kütüphanesi kullanıyorsanız o framework bu işi yapacaktır.
python node vs redis
php.ciler mamcache kullanıyor

eski sistemler için pansuman tedbir var
sticky session deniyor buna
ilk gelen cookieye bundan sonraki requestlere o sessionid.yi dolaştır diyorsunuz
bu mümkün ama bunların açtığı başka sorunlar var
yük dengesiz dağılmasına sebep olabilir session timeout oldu birinde 10 diğerinde 40 kişi kaldı
sticky session yapsanız bile uygulama ve db cache ile sorunum var
bu cache bişey değişirse diğerine söyle değiştirsin diye birşey yapmak gerek (eriction?)
veri tabanı gibi memoryde tutuyorsam adı memorygrid bunu redis vs yapar

db.yi çoklamak maliyetli
sistem mimarisi açısından iki tane çoklayabildiyseniz gerisi gelir.
fkm felaket kurtarma merkezi
başka bir mesafede başka bir kıtada olması gerekiyor

hsbc bombalama olayı,
istanbul iki telli de su basması olayı,  datacenterı su bastı

fkm kuralları yüksek erişilebilirlikten farklıdır tamamen manuel çalışmalı, yetki erişimi farklı olur, 

örneğin mongodb yataya büyüyebilir
en az 3 tane , primary ve 2 tane replica yapıyorsunuz
leader election için tek sayı olması gerekiyor
oylama yaparak lider seçiyorlar
splitBrain deniyor buna protocol adı gossip bu arada :D

2 node'a düştüğünüzde sistem durur sistem lider seçemiyor replica yapamıyor

sharding yataya büyüme yapıyoruz 3 * 6 =18 tb lık yapamayacağımız için 300gblık diskler alıyoruz yataya doğru
herşeyin bedeli var
bunun önüne bir tane daha load balanver kouyorsunuz
mongodb.de mongosh var
300 gblar halinde 6 tane kendisi bölüyor sharding yapıyor lazım olunca istediğine dağıtıyor 
1tb dan az datanız varsa hiç sharding vs uğraşmayın
mongodn dokuman veritabanıdır becerileri yanında zaafları da vardır
dokument keyvalued graph tipinde 4 tip nosql 
redis keyvalue gibi davranır ama cache

rabbitmq redis elasticsearch
niye tercih ettiniz
google üste çıkmış herkes onu yapmış 
aynı işi yapan birisi sizin için daha doğru olabilir

var olan iyi bir arguman birisinin çözümü vardır iyi bir arguman
ama birisi öyle internette yazdı diye doğru olacak diye birşey yok
sizin sorununuzu çözecek mi 

mongo transaction garanti etmezzz saga gibi yöntemlerle sizin garanti etmeniz lazım

redis gibi bir dağıtık sistem hayal edin
3 tane kurduk
veriyi böl replicalarını al, sharding yaptık 300 gblık 100 100 100 böldük replica ile 600 gblık yer harcadık 300 gblık tek node yerine hem yaydım hem replica yaptım
100	100	100
A	B	C
A'	B'	C'

cache sistemlerinin yataya büyüme ihtiyacı diskten fazla çünkü ramler pahalı


ihtiyac duydugunuz ram miktarı artıyorsa mutlaka yataya büyümeli memorygrid buna deniyor

konuştukları portların firewalldan açılması gerekir kendi iç konuşmalarını yapacakları portlardan bahsediyorum
kendi iç sanal networklerinin olması sağlanabilir
hasntcase kümesi ? konfigürasyonlarının düzgün yapılması gerekir

bizim hasntcaseler bazen korkunç yavaşlıyor
bazen test için geliştirici servis açıyormuş o yüzden
böyle durumlarda şirket için network ayrılmalı 
kubernetes zaten kendi kapalı iç networkleri ile gelir
önceden direkt ip ile internete eriştiği için sürekli paket gönderip kapatıyordum :D
podu geçip içerideki servislerinie erişebilmek için tcp protokolünü ingrents izin vermiyor worker node ipsine routing yazılacak o da içerideki node'a yönlendirecek bu iş low level yapabilir zor.

2 ) Kümeleme ihtiyacının diğer nedeni yük dengeleme
önce metric toplamam lazım, performance ihtiyacı ne
ne kadarlık bir request gelecek
saniyede on mu saniyede üç bin mi
reponse süresi, saniyedemi milisaniyede mi dakikalar sürebilir mi cevabım

müşteriden almak zor olan pig time bunun için monitore izlemeniz gerekir
akşam 5 te yük geliyor günün geri kalanı yatıyor
sistem var senede iki kere yük geliyor
buna göre çzöüm lazım
genel geçer hal yükü kaldıracak kadar yataya büyümem lazım

manual conf yapabiliriim bir kısmı bu makineye bir kısmı bu makineye diye yükü dağıttım fakat
yük dengeleme ve yüksek erişilebilirlik ihtiyacınız aynı anda ise yükü kaldırabilecek sistemi çoklamalısınız

yükün nereye geldiği sorunuz var mutlaka yük testi yapmalısınız
yük monolithte birine gelse bile hepsine gelmiş gibi davranır
mikroservis de sadece birine geliyor onu çoklamam lazım
şuan manualdan bahsediyorum
ilk darbeyi load balancer aldı kaldırdı 
ikinci darbeyi uygulama sunucusu aldı onu da kaldıracak hale getirdik
bu sefer db sonucu patladı
mutlaka yük testi yaparak elinizde metric olmadan hissi kablel vuku ile yapamazsınız
apache jmeter en çok kullandığım yük testi aracı ( JMeter ile İlk Performans Testi https://medium.com/@ozaneseriu/jmeter-ile-i%CC%87lk-performans-testi-d17fdb1a85fb)
hazırladığım testi paralel yap vs gibi testler yapabiliyorsunuz

network izleme zabbix vs ne kullanıyorsanız bu kadar cpu ram kullandık hepsini gösteriyor
yük testi yaparken de ihtiyacım var buna

yük testi kafanıza göre yapamazsınız canlı sistemleri çalıaşamaz hale gelecek tüm ilgili tarafların orda olması lazım
conf.da şunu değiştirip deneyelimler olacak
amaç normal kullanıcı dışında sistemi kitleyecek kadar yük bindirecek

aynı saniyede on requeste cevap vermek amaç
oldu diyelim sistem patlayana kadar deneyip sistemin sınırlarını öğreniyorsunuz

db dikey büyüyor exadata satıyor ekonomik sınır var fiziki vs dışında proje iptal oldu

bir zamanlar turizm uygulaması yazarken
müşteri geldi yeşil gözlülere indirim yapacağız dedi
olasıklar üzerinden pandemi vs bişey yapamayız olabildiğince hazırlıklı olmak lazım ancak başa gelince çözülür bazı şeyler

endonezyadaki tsunami sırasında özel bir tır containerlar sipariş edildi içinde pcler üst olarak kullanabilecekleri.

ekonomik sınırda exadataya bir milyon dolar vermek mi mimariyi değiştirip baştan yazmak mı ya da müşteriyi hedef listesinden çıkarmak mı?


byte hesabı yapmayı bilirim 512 mb sığdırmak için 30 bite sığacak şeyi 1 bite sığdırmayı bilirim şimdiki arkadaşlar ram bolluğunda doğduğu için !

javada garbage colleciton eğrisi ram kullanır sınıra gelir çöp toplayıcı çöpü toplar M grafiği tarzında yukarı küçülen eğriler şeklinde bir grafik çizer
bir tomcat içinde 5 uygulama jvm için doğru değil her bir uygulama ayrı sunucuda sunulmalı ayrı ayrı yapmalısınız
her uygulama deploy ettiğinizde verilerin yüklenmesi metaspacesize var ya... oemkiller çalışırsa iyi çalışamazsa daha kötü ?

memoryleak sızıntı memory kaçağı var
çoğu geliştirici ram kullanımına dikkat etmediği için gereksiz ram kullanıyorlar
ya daha az okunan kod yazarsın ya da daha fazla ram kullanırsın
yazılımın daha optimize olması onun okunaklı olmasından daha önemli



Eğer ki sistemi düzgün tasarladı ve mikroservis kubernetes kullanıyorsanız?
autoscaling yaparsınız yük sınıra ulaştıysa düştüyse oluştur bitane daha ya da düşür onu tarzında

elinizdeki kaynağın boşta yatma süresi vs bunları manuel yapmak zor
k8s bonusu en önemli nedenlerinden biri bu
üç servisim var yük gelince saat 5 te iki tane daha node açıyor vs autoscaling yapıyor
yük dengeleme sticky sessionlar vs doğru yapılmışsa k8s bunları yapar.


hybrit cloud çözümü ile gelir openshift rancher
haa worker nodelarım yetmiyor yeni worker node açayım diyebiliyor

kişisel verileri geçtim ekonomik finansal verilerimizin bile datacenterı yurtdışına çıkmış durumda

gider bütçesini güzel güzel anlatttılar
gelir bütçesi kalemi yok lazım olunca gidip ceza kesiyoruz :D

oomkiller linux sistemde ram biterse en fazla ram kullanan öldürülür (Linux - Out-of-Memory Killer (OOM killer) )
tomcat önüne apache web servis koydunuz
çalışma mantığı forktur
ölen tomcat olur apacheler yaşamaya devam eder

//mola sonrası
servisimiz çalışıyor da küme sağlıklı çalışıyor mu
kümeyi izlemeniz gerek

bunun için düzgün bir distributed cache sistemi kullanmanızı tavsiye ederim
multithread bir kod yazıyorsanız programlama dilinden bağımsız threadsave dir bu fonskiyon diye belirtir dokümantasyonda
single thread çalışabilir kimisi orda da benzer şeyleri yapmazsanız frontendiniz de dağılır
bunu daha başta yazarken düzgün yazılmalı bunu yazarken bile kullanılabilir  distributed cache sistemi 
cache sistemleri bunların hepsini yaparlar siz kendiniz yazmaya kalkmayın 

Lider nasıl seçilecek hangi nodeun lider olduğundan nasıl haberleşilecek
zookeepers consul k8s vs bunları yapıyor.

hiç lider yoksa ne olacak?
hazır kütüphaneler var javada springde içine kütüphane koymuşlar
rubyde bu işi yapan gem var
lider seçimi için kullanılan bu araçlar service discovery hizmetini de bonus veriyor

Veritabanı Değişiklik Yönetimi !!! değişiklik yönetiminiz ve politikanız olması şart
veritabanı kolan ekle sil tablo ekle tipindeki değişiklikleri düzgün yapmıyorsanız, autoscale ederken mikroservisiniz batar
flyway ve Liquibase opensource ürünlerini kullanabilirsiniz veritabanı değişiklik yöntemi için
tek tek sqlleri yazıyorsunuz bu sorguları tek tek uyguluyor
o değişiklikleri tabloları dosya ismi üzerinden tutuyor
flyway rollback yetenekleri yok sürüme çıktınız eski sürüme döneceksiniz.
Liquibasede var, rollback becerisini ayrıyeten yazarsanız böyle bir şansınız var.
birden fazla kullanıcının geliştirme yaptığı yerlerde liquibase hayat kurtarıyor.

LiquiBase diff de alıyor geliştirici testlerinde
data değil ddlden bahsediyorum
bunları iyi yönetmezseniz deploy çıktık db bozuldu olur hangi düzenli deployment olacaktı ?

yazılım standardı politilası
hata çözüm politikası
düzenli sürüm çıkartma politikası
iş takip sistemi 
sürüm takip sistemi
kod kalite ölçümü
kod güvenlik ölçümü
veritabanı değişiklik yönetimi politikası
belgeyi ehliyet alır gibi değil iso smmı belgesi vs işi en işi şekilde yaparak almalısınız

mac hızlı açılması ilk ekran resim açılır arkadakileri peşi sıra yapar, bazı siteler de bunu uygular

database per service her servisinizin ayrı veritabanı var
mssql hana postgre vs olsun bir server içinde n tane db tanımlanabilir
ya da sisteminize bağlı fiziksel serverlara ayırırsınız 
burdaki problem aynı dbdeki tablolara birden fazla yerden erişmemesi?

//mola sonrası
ilişkisel değilse dbniz mongo ise buna uygun da kullanmalısınız
mongo yarı schemalı diye geçer, LiquiBase eklentisi vardı bunun için
önden bir şema tanımlanıyor
hiçbir attribute silmiyorsunuz hilesi var ama sürekli alta ekliyor bir süre sonra şöyle birşey oluyor yukarıdan aşağıya uzayan bunun de yönetimi lazım

httpheadera koyuyorsunuz
dokuman içine gömüyorsunuz
vs sürümle beraber veri değişiklik modelini takipe ihtiyacınız var yapmazsanız mikroservis zul olur

//öğleden sonra
bazen bilerek asenkron isteriz
http kendisi senkron çalışır request response
o iş yapılınca cevap vermemiz gerekiyorsa wbook deniyor karşılıklı endpointler tanımlanıyor böyle bir asenkronite sağlanır
e postalarla gelen çok eski olan message servisleri var
ürün aynı isim farklı hepsi birer mq implementasyonu kafka dahil
serviceBus MessageQueue Distrubuted Event EventSourcing

bir tane istemci mesajı atan kişi kuyruğa mesajı atıyor bir de mesajı alan var producer ve client şeklinde
P -> boru -> C
	     Q
	     |
	     |
C <--  boru
FIFO ilk giren ilk çıkar messageları sıraya sokar
bin kişiye e posta atıcam anında gitmesinin karşılığı yok e posta kendisi asenkron zaten
cpu boşken e posta atayım gibi işler yapmak için mq sunucular şahane çalışır


bir olay oldu siparişi kaydettim ve mesaj attım Distrubuted Event deniyor ?
mesajı ürettiğimde yerine ulaşmasını garanti etmem gerekiyor mu, belli bir zaman aralıgında ulaşmasını garanti etmem gerekiyor mu, mesaj kaybolursa bunu geri alacağımı garanti etmem gerekiyor mmu proje bunlara göre değişir
EIP  apache Camel var javada EIP Enterprise Integration Patterns var (https://camel.apache.org/components/4.8.x/eips/enterprise-integration-patterns.html)
nodejs için crosser nodered

throughtlink yani boğazlama bir anda gelen requestleri kuyruğa alıp ben bunları birer birer işleyeceğim diye kaynağa göre mq sistemler bunu planlıyor
1960lar kadar varlar mq sistemler eposta sistemler kadar eski
burada izleme de yapabiliyorum 
ETL ?

AMQP advanced message query protocol
MQTT
STOMP js browser tarafında kullanılır bunlardan birini kullanın.

kafka message sunucu gibi davransa da aslında bir dokuman tipinde?
mq yerine eventsourcing kafaka ile yapılır gibi bir algı var ama zoomkeeper ile de uğraşmak zorunda kalırsınız
standart protokollerden birini kullanamazsınız

arkada hangi ürün olduğu beni ilgilendirmiyor
aktivemq zeromq rabbitmq IBMmq olur hangisi olduğu benim yazılım açısından farketmez bu operasyon açısından çok önemli
aynı işi yapan ürünün rekabeti performance becerileriyle işi ne kdar kolaylaştırdığı ile belli olur

ama karar verirken diyelim tüm stack benim java ise içine rabbitmq sokmam onun yerine aktivemq kullanırım. ama bu javaysa rabbitmq kullanılmaz değil bu performance farkı vs bakılmalı
javada redis kullanılmamalı, javadaki .. redisten yüksek

twitter redisi kullanabilmek için cluster düzgün çalışsın diye önüne kod yazdı

as400e IBMmq ile bağlanmak zorundasınız
size önce freeproduct bişey verir çıkamazsınız ordan yine onun bir ürününü kullanmanız lazım ve legacy systems

bir bankanın check sistemi için bir hafta aradılar masanın altında sehpa niyetine kullanılmış :D

doğru iş için doğru ürün kullanmanız lazım

serializing ya da marshalling ypacaksınız diyelim networkte diskte saklanacak hale getirmem gerek
rediste json yapacagım vs eğer javada kendi nesne yapısını binary göndermem yetiyor.
mq yerine httpsunucunuzu da dürtebilirisiz wbook ama o srvisin çalışıyor wbooku dinliyor olması lazım
ama mq cpu kullanımını optimize eder gün sonunda kuyrukta bekleyenler gönderilir

jenkins gibi bir servis işinizi görür mü soruna göre düşünün düzenli derleme ve deployment için zaten kullanıyorsanız zamanlanmış görevler için de iyi çalışır.


k8s 'in job diye bir deployment type'ı var. openshiftin de o yüzden var.

springserviceBus görünce de bir kuyruk sunucusunu anlayın farklı adları bunlar. serviceBus MessageQueue Distrubuted Event EventSourcing

bir consumer değil iki consumer istiyorsak topic , cevap kuyrugu tanımlamak tipinde farklı yöntemler uygulanır.

EventSourcing dağıtık event mekanızmasına ihtiyaç duyarsınız bunları muhakkak ekleyin uygulamanıza.


Mikroservice Tasarım Desenleri 15 taneden bir kısmı
Saga
Database per Service
Circuit Breaker
CDC (change data capture)
Event Sourcing
Backend for Frontend
Apı Gateway
Sidecar
Service Discovery
CQRS (Command Query Responsibility Segregation)

mikroservis tasarım deseninden önce normal tasarım desenini kullanmanızı tavsiye ederim
DRY dont repeat yourself   kodu kopyalayıp yapıştırmayın çoğaltmayın kütüphane yapın
lütfen kendinizi tekrar etmeyin

özellikle uzmanlık gerektiren cripto algoritmaları güvenlik multithread tipindeki kodları yamamaya çalışmayın kendiniz yazmaya çalışmayın, kullanın anlayın sorgulayın

kıss keep it stupid simple olabildiğince basit tutun kodlarınızı

reactive programlama denilen programlama türü var kafadan bütün yazacagınız herşey asenkron çlaışır yazım tekniği ve thread yönetimi bambaşkadır korkunç performanslı çalışır ama sizin ona ihtiyacınız var mı ? siz reactive yazmayın daha uzman apıgateway yazan insanlar yazıyordur 
hazır yazılmış tonla apigateway var

spring bile mvc olanı yazdı reactive olanı kimse okuyamadı

eclipse vertex, aka tipinde reactive var gerçekten ihtiyacınız yoksa uzak durun onun yerineee

MVC tasarım deseni var.
model view controller ayrı yazılır java
node npm paket sistemi vs
özellikle model veriniz bunlar tekrar tekrar kullanılacaktır
view sunum katmanı xml olabilir mq'ya mesaj atan brişey olabilir soap zarfı olabilir bir servisim aynı anda 5 sunum olabilir ama iş kuralları takip eden controller bir tane olmalı
bu deseni recursive biçimde eğrelti otu tipinde yapın ayrı ayrı yazınız

persistent veri katmanı database, sunum katmanı vs mikroservicede de böyle ayıracaksınız...

	MODUL1    |    MODUL2
V
C
M


view katmanında htmldi rest istediler sonra 180 formda değişiklik yapmak zorunda kaldım başta viewcontroller kısmını da ayrı yazmalısınız
bir model controllera bir controller bir vieww bağlı olamaz
arcunit gibi kuralları yazıp bağımlılık alamaz vs şeklinde kurallar yazamaz.
geliştiricinin biri yanlışlıkla yazdıysa kolayca buluyorsunuz

model isimleri controller isimleri böyle verilir diye bir kural koymalısınız

DDD domain driven design buradaki domain bir business domaini tarif eder
her bir dokuman mongoda bir domaine denk gelir
bir domain diğer domain ile apiler üzerinden haberleşmeli
sepete ekle sepetten çıkar şeklinde
bazı abartılı olanları mapper kullanmayacaksın vs tarzında şeyler uygulamıyorum feature implement ediyorum ben
entitynin en uca kadar gitmesini tavsiye eder ama benim domainlerim başka bir tasarıma sahiptir 

ilk validation uı 2. viewda olur devamı controllerda olur
üçünüe de aynı validation kurallarını uygulamak için başka biryerde yaparım ve yine ddd ihlal ederim yerine göre

ddd'ye ek olarak iki dizaynı birleştirip CQRS ve command driven designi birleştirip DDD gibi kullanıyorum, commandbase çalışacak ve abstractları da kullanıyor

executer ve commandlarınız ayrı paketler commandlarım queuedan pipedan akıyor bir başka servise de pipelayıp gönderebilirim 
bunun için de convention kurduysanız eğer uzun sürse de sağlam olur mikroservis olmasa da monlith olsa da bu tip yazıyorum ben
scaffolding aracıma diyorum ki üret... create user update user delete user 
mapperları üret bütün bunları scapffolding aracı üretti
model sınıfının attribute listesi benim yazmam gereken ve validation kuralları geri kalanı scapfolding yapıyor

java jakarta içinde şöyle bir anotation kullanırsın diyorsun bunları üret derleme sırasında uı.da kullanılacak olan json skema.sını da üretiyor
eğer yazacagınız uygulamanın yazma süresi bir aydan uzun sürmüyorsa unutun bunları nasıl istiyorsanız öyle yazın :D yanlış yapsanız da bir ayda yeniden yazarsınız

kurum içinde application framework oluşturun bu tip kuralları belirlerseniz başka projede bir aylık projeniz bir haftada yazılır

java jakarta ee patternleri var bunu böyle yapma ben yaptım sen yapma tarzında antipatternler var bilmeniz ufkunuzu açar

en basit patten singletondır ama 
gerçekten singlethon yazamazsınız java node vs c ya da c++'ta yazarsınız
garbage collectordan dolayı ama yakın bişey yazmanız yeterli

(Scaffolding using Spring.io, Scaffolding Spring Boot, Freemarker and JDI - Building DDTJ)

//moladan sonra

Event Sourcing loosely coupled zayıf bağlantı eventi yakalayıp yakalamyacağı ile ilgilenmeyip daha sonra bunu alıp başka birşey yapabilirsiniz fırlat unut tarzı şeylerde kullanın
bazı eventlerin transaction olmasını isterseniz bu iş Event Sourcingde yapmayın

asenkron longrunning transaction 


//postgre ile yüksek erişilebilr yapmak zor mongo ile replication bilmemnesini kendi yapıyor

transaction patterni için de saga kullanıyorum
servisler arası dağınık transaction yönetimini de saga ile yapıyorum


Database per Service kullanıyorsanız CDC (change data capture) kullanmalısıınz çünkü verileri tek başına ne yapacaksınız rapora da ihtiyacınız vardır

karar destek sistemleri oltp (online transaction proccesing) ve dss'in (decision support systems) işlevsel olabilmesi için bir araba indexe ihtiyacım var ?
dataları toplayıp etl camel yapıp rapor alacak duruma getiriyorsunuz
oltpde normalization
dssde denormalization yapmalısınız. 
datawarehousing ile dataları topladım ordan rapor aldım
güncel olmayabilir dezavantajı
ama güncel veriyi son kullanıcıya gösterme zornululuğunuz varsa memorygrid yapmalı, penthao vs ile yapabilirsiinz
uygulamaları servisleri bile ayırıyoruz insert yapacaksan bir db.ye git vs
OLTP:
1- It is desined to support business transactional processing.
2- It is designed for running the business operations.
3- Volatile data.
4- Current data.
5- Normalised data.
6- Application oriented data.
7- 3-6 months of transaction history.
8- Desinged for clertical operation.

DSS:
1- It is designed to support desition making process.
2- It is designed for analying business operations.
3- Non volatile database.
4- Detailed data.
5- denormalised data.
6- Subject oriented data.
7- 5-20 years of transaction data.
8- Desinged for manageral access.


OLAP systemleri excel gibi düşünün 
olapa uygun summerize edip kümelenmesi gerekir


birbaşkasının problemi sizin için görünmezdir- otostopçunun galaksi rehberi kitabı -douglas adams
42 sayısı değişim ve büyük kararlar almak anlamına gelir.

Backend for Frontend
frontentimin bazı ihtiyaçları var
bazısı a servisinden bazısı b servisinden gelmeli ufaktan merge olmalı bunlar
ama bu sırada yükü browsera vs bindireceğim
ordaki iş kuralları tanımlayabilecek miyiz 
bunun arkasına backend servis yazılır cacheler frontendin istediği şekilde diğer servislerle konuşur ordan data talep eder, db.ye erişmez.

asenkron atabileceğiniz şeyler rapor gibi vs olur
ui implementasyonlarında ui cevap bekler senkron olmalı, 
infinite scroll gibi  başta 3 kayıt getirirsin psikolojik çözüm
isteğiniz hazırlandı e postanıza gelecek şeklinde psikolojik çözüm yapmalısınız

Circuit Breaker
benim sipariş servisim cari servise erişmek istiyor ama o sırada cari servisim kapalı standart http request sürem ayarlamazsanız 2 dk. 
2 dk beklerken 3 kere daha tıklar ve 6dk.ya çıkar ve timeout gelir bundan sonraki isteklerin atılmaması gerekiyor buna Circuit Breaker denir devre kesici
Circuit Breaker dener cari servis açıldıgında cevap vermeye başlar, bunlar multithread çalışırlar çünkü ilk thread denedi yanıt alamadı kapattı
retry tekrar deneme patterni var on saniye bekle tekrar dene 20 saniye dene tekrar dene belki pod geldi k8s'te.
kaç deneme yapılacağı konfigure edilir, retry yaparken apiyi denersiniz.

Apı Gateway
internal uygulamnızda ben diyelim bankayım dışarıya api açıyorum
kaç request atabilirsiniz dakikada günde bütün bunlar apigateway üzerinden implement edilir
kong vs gibi ürünler var
(What API Gateway to choose: Kong, Gravitee, Tyk or HAProxy?)
bilink throatlink vs yapan 


Service Discovery,
arka tarafta bir service' e gidecek o servis nerede vs dns gibi düşünün
servis adım bu instance bu tarzında k8s de yapar bunu
Service Discovery registration sağlar
dns'e elle kaydediyorduk tek farkı service discovery direkt ben buradayım diyor
dns.ler de artık programatik gerçi.
zayıf bağlı olma şansı yok kesinlikle conf etmelisiniz binding sakın yapmayın
statefull deployment deniyor ama yapmayın, programı yazan arkadaş ille ip adresi istiyorum diyor :D
k8s'in bir becerisidir.ama dockerswarmda da çalışın istiyorsam zookeper vs kullanmam lazım.
 
CQRS (Command Query Responsibility Segregation)
komutlarınızla sorgularınızı birbirinden ayırın apileriniz
delete update vs commond
get query sorgularınızı vs ayırın hatta abartıp mikroservislerinizi ayrı yazın der pattern
bunu ayırınca graphquery elde edersiniz
queryler read onlydir cachelenir
ama commondların başka ayrı özellikleri var. ayrı tasarlarsanız yükü dengelemek mümkün hale gelir
ihtiyacınız varsa bu deseni kullanın ille kullanacağım diye iş yükü yaratmayın kendinize

Sidecar motorun yanındaki sepet gibi
sen bu imageı deploy ederken yanına bunu da ekle
ilk tasarım yaparken düzgün kurgulayın sidecar ile yaparım vs yapmayın.
ab testi , red green testi yapmak istiyorum apigateway yok circiut breaker yok, sidecar bişey ekliyorum alıyor başka servise gönderiyor vs 
bu pod ile gelen bişey.
iç networkü kancalıyor asıl koda dokunmadan yapacagınız bişey oluyor
network araya girme yama vs yaparken çözüm sağlar ama tasarım deseni olarak seçmeyin
sonradan conf ile bişey eklemek karmaşayı artırır izlemek zorlaşır
geliştiricinin haberi yok loguna bakıyor yok çünkü sidecar o kesmiş

//12.02.2025 Çarşamba

api kırmak , abi kırmak
api için declaration yapıyorsunuz methodum şu şu paremetreler alır
yeni bir method geliştirdiniz apinizi şu şu özellikler eklediniz api kırdınız
major versiyonda göç planlamanız gerekiyor yani iki farklı uygulama gibi

abi kırmak
methodum ve parametrelerim duruyor ama fonksiyonun yaptıgı iş aynı değil

siz minor sanıyorsunuz major çıkıyor bugfix sanıyorsunuz minor çıkıyor 
herkes semantic versioningi doğru yapmıyor

SAGA
transaction problemini çözmek için kullanılan bir desen

ACID
normalde transaction sisteminin garanti etmesi gereken şey yaptıgınız işlemin tutarlı bir bütün olarak yapılıp yapılmadıgını garanti etmek
transactional asıl dbde kaydınızın tutarlı yazılıp yazılmadıgını garanti eder 
illa db bunu vermek zorunda değil 
mq sistemleri ben transaction destekliyorum der consumer işinin bitirene kadar işlemin tutarlı olacagının ya da olmayacagının garantisini verir
transactional relational dbde çok önem taşır , ACIDi garanti etmek için dağıtık çalışamazlar, dikey büyürler
aynı anda iki kişi birden çalışma yapıyorsa db.de o alanda db kendini gitlemesi lazım
log sürelerini ne kadar kısa tutabildiği ile ilgili bazıları page kitler, bazıları table kitler, okurken kitlememiz de gerekibilir bazen okuyup o veri için işlem yapacaksam
uygulamada atomic integer, atomic long diye geçer, multiconquirency kilidiniz okumaya izin verir güncellemeye izin vermiyor olabilir farklı yorumlar var sizin ihtiyacınız olan hangisi, örneğin javada syncronize koyarsanız java compileri single thread kullanacak şekilde kitler okuyamaz bile, ihtiyacım bu mu çoğu zaman değil
javada ayrıca log kütüphanesi var while içine konulur while(getLog()) bu tür apiler benzer notasyonda yazılır
işiniz bittiğinde de geri release etmeniz lazım. etmeyince deadlock olur. iki farklı thread birbirini bekler. eğer ki bir timeout varsa ona kadar yoksa sonsuza kadar bekler.
sistemde yük yok bişey yok cevap yok thread havuzunda bütün threadler dolu ama işlem yok
db.de çogunda deadlock detection sistem var eskiden yoktu. mysql postgre mysql var. %99.9 arada deadlock sandıklarınız feature da olabilir.
transaction açık duruyor begin tran dedmişsiniz commit ya da rollback yoksa..
ya da içinde başka işlemler içeren yerlerde yapıyorsanız sistem bekler, olabildiğince küçük sürelerde transacitonal yapılması lazım.
transacional timeout süresi değiştirmediyseniz bellidir
transacional timeout süresi  5 dk proxy timeout süresi 2 dk ama cevap yok uyumlu olmalı bu süreleriniz
proxy web sunucularınızı kim ayarlıyor apache nginx 
3-5 dk süren işlemleri arka tarafta yapın kullanıcı browserında 5 dk beklemesin ya da engelleyebilmek için frontendde ekran kitliyoruz 


excelde jsonda vs 365bin veriyi işlemek yerine bach streaming yapıp bloklar halinde kullanında dom kütüphaneleri yerine socks kütüphanelerine okuyarak ilerleyin, yoksa veriniz ram'e sığmaz
ben her batch commitlerim 100 kayıt 100 kayıt atarım, 100 kayıtın tutarlı oldugunu bilirim
hangi 100 kayıtta patladıgımı biryere atmam lazım ki
1000 kayıtlık bişeyde 500 kaydı attım gerisinde hata çıktı tek bir kayıtta atmaması lazım nerde kaldım hangi kayıtta
uzun süreli transaction açmamalısınız.
(connection pool denen yöntemler thread pool yöntemleri var
her zaman deadlock olmaz ama threadler doludur feature deme sebebim bu
100 connecitonun 5 ini kafadan aç lazım olunca kullan
ama memoryde yer kaplıyor her daim açık olan da
bir dk boyunca boş kalabilir sonra kapat
jvm.de max 300 thread olabilir şu kadarı açık kalsın şu kadar süre açık kalsın
kullanıcı yavaşlıktan şikayet ediyor, yük yok deadlocktan önce bakacağınız yer,
pool configürasyonunuz yanlış ! monitoring anlamında bakmanız gereken yer heryer
http connection pool ya da biryerde sıraya girmiş bekliyorlar.)

bibirinden iki bağımsız ayrı makinede transaction bloguna ihtiyacım varsa ne yapmalıyım? eski bir problemdir bu.
kod çalışıyor ve iki ayrı db üzerinde işlem yapması gerekiyor ve transaction yapmamız lazım, bir de dosya sistemi koydum (transactional dosya sistemi henüz yok)
two face commit denen iki fazlı commit denen bir yapı var, dblerde kendi içlerinde bu çözüm var,
connection stringleri farklı javada JTA kütüphanesi ile geliyor, iki db.ye de kayıtları koyuyor commitlemiyor hata yoksa commit yapıyor en son.
commit yaparken hata alıyorsanız diskte vs hata var ve geri alınır
transaction ne kadar uzunsa replication gap'iniz o kadar uzundur.

db kendi desteklemiyorsa;

//mola sonrası
transaction olmayan yapılarda nasıl yapacagız?
kayıt silme işlemi ise kaydı geri getirmeniz lazım
ya da soft delete yapmanız lazım silinmeyenleri getir şeklinde
command pattern kullanıyorsanız command bu tersi bu şeklinde..
silme noktası açısından da bazı şeyleri tasarlamanız lazım
infinite state machine sonsuz durum makinesi state durum makineleri konusunu hatırlayın uygulama tasarımı yaparken bunu kullanır ve delete yapmazsınız, soft delete yerine bunu kullanıyorum
örneğin sipariş kodunu ilk oluşturdugumda taslak kısmında duruyor tamamladı diye müdürüne gönderdi onay state'ine geçti yayınlandı artık event fırlattı
müşteri itiraz etti eksik girmişsiniz dedi tekrardan edit moduna aldım iki gün sürdü diyelim tekrar onaya gitti yeni durum bu
hepsini loglayıp kullanıcılara blame verebilirsiniz
en son sipariş iptal oldu diyelim siliyor muyum hayır iptal state'ine alıyorum. delete operasyonum hiç olmadı farkındaysanız. işlemin tersini alma operasyonuna çözüm olmalı bu.
hangi durumda hangisine geçilir önden tanımlanır state machinelerde bu her bir state arasındaki işleme action denir.
uygulama geliştiricinin bunu önden tasarlaması gerekiyor
java enum içinde yapmak en basit hali
stateless kütüphanesi de var bunun için
bunun bir de abisi var,
BPM adı da BPMN business process management notation,
sistem analizleri tasarlar çalışır olması lazım ama gerçek hayat böyle değil
start -> servicenode(human task var içinde) -> kararr noktaları -> betik taskı, eposta taskı
süreçi analiz ederken, müşteri ile konuşurken kullanıyorum ben bunu.
BPMN engine kullanabilirisiniz;  activitiy bonito vs zibille ürün var 
BPMN' ler gelişmiş state machinelerdir
satış süreci ipucu ile başlar lead toplar satış süreçlerinde bunlar, en son fırsat ya kapanır ya da teklife dönüşür, kabul ettiler sipariş aldınız, hizmet ya da mal şeklinde, parayı kim alacak nasıl alacak fatura kestiniz ödeme aldınız süreç ancak bitti, her birinin süreç akışı içinde yeri var
bunun transaciton ile ne alakası var?
bu iki bir iki aylık süreç 
long running process ; uzun süren işlemler denir buna
cari sistemine girip sipariş sisteminden bilgi almanız lazım misal, bu etkileşim tutarlı mı bunun için bir çeşit transaction kurgulamam lazım.
bunun için geldik sonunda SAGA'ya
bu hikayenin hepsini bir loga dolduruyoruz, bu logun adı SAGA
sonra herhangi bir şekilde sizin sisteminizin hata kabul ettiği bir durumda geri dönmeye başlamanız gerekiyor
SAGA loguna tarihçe koymuştum ya tersine işlem ne yapacaksam yaparım,
command patterni kullanabilirsiniz zorunda değilsiniz jakarta içinde bu işi URL ile yapıyorlar.
orcestration yapan bir servis SAGA'yı yönetir, ya da eclipse'de long running kütüphanesi var onu kullanırsınız
ya da SAGA kullanan kütüphaneler var begin saga commit saga rollback saga tarzında kullanıyorsunuz
işlemin tersini nasıl alacağız bunu eninde sonunda bizim yazmamız lazım, ürün kütüphaneler var ama geri alacağız nasıl alacaıgız eninde sonunda geliştirici yazacak
mongoda tüm tarihçeyi tutan javerse var.(The Leading Framework for Object Audit and Diff in Java- JaVers is the lightweight Java library for auditing changes in your data.)

Tüm loglama sistemleri çok yer kaplar, sen istiyor SAGA şeklinde opsiyonel tutuyoruz. 

bütün bu sistemlere bir yan sistem de eklemeliyiz
housekeeping

mongoda yeni bir nodeaçar ona replica olur 
postgrede vacum kullanılır
reac diye bir db.de silme komutu yok çünkü daha maliyetli silmek tutmaktan diyor gerekince housekeeping yapıyor

B Tree algoritması ya da varyanti ile tüm veritabanı sistemleri veri tutar
dolayısıyla bir arama yapmaya başlayınca hızlıca veriyi bulur ama veriyi tekrar tekrar yazar ağaç hiyerarşisi ya da indexinize dahil
runtimeda index yanlış kurulursa sürekli alta ek ya da ağaç sağa kayar
insert update delete işlemlerinizdeki tüm işlemler indexte işlem yapmayı da gerektirir, ne yaparlar dbadminler yeniden index oluşturur
Bu tür sorunlara çözüm için de housekeeping yapılır
gerçekten lazım olan veriyi farklı yere nadir bakacagınız veriyi farklı yere koyarsınız.

//mola sonrası
kullandığınız db.e göre last page insert olan sistemler oltp sürekli veri giren insert olan sistemlerde tersine kayıt almak updateden daha az maliyetli hale gelebilir?
5 yıldan fazla veri kanunen saklanmamalı, unutulma hakkı, 5 yılı da digitalde tutma zorunlulugu yok kağıt olarak da tutuluyor,
sağlıkta on yıl, adli vakada 100 yıl,anominize etmek de çözüm olabiliyor artık, crypto olarak saklanmalı,

intel ve arm.da açıklık var tüm cpuları değiştiremeyeceklerine göre şuan örtbas ediliyor

ruslar bir unixe honeypot koyup yıllarca bu unix sistemlerinin kullanıldıgı heryeri izliyorlar
pardus ordudaki birim nato ürünlerini kullanınca komutlar gelmiyor vs
Tubitak UEKE başlattı ancak şuan debianın paketlenip sürüldüğü hale dönüşüyor
pardus önce sunucularla başlayıp community isteyince masaüstüne yönelseydi...
pissy paket sistemi ile başlayıp debian redhat baz seçilmeyip üzerinde tonla ürün geliştikten sonra vazgeçtik değiştiriyoruz olmaz

SAGA'ya geri dönecek olursak bunlar desen birebir kullanmanız gerekmiyor.
hem SAGAyı hem aradaki networkü ilgilendiren 
mikroservis rest üzerinden konuşur 
kullanıcı ile ne tercih edeceğiniz tartışma konusu gidip gelen verinin tipi çok önemli
binary protocollerle mi konuşşsa sunucular vs bakınıyordum
eğer ki veriniziniz önemli bir kısmı stringden oluşuyorsa binary protocollerle uğraşmanızın anlamı yok çünkü verideki stringleri sıkıştırılamıyor
ama atributelar tekrarlanıyorsa avantajı olur. tekrarlandıgı durumda bile bir metricde izlenebilir
http client ve http server arasında transparan iletişim var
önce zipleniyor sonra açılıyor. string verilerden zipin sıkıştırması binaryprotocollerden daha iyi olabiliyor
iot cihazi ise json kullanmayın tabi binary kullanın.

log için sagaid gönderiyorsunuz http headerda, interceptor maliyeti fazla.
api version dahil headerda göndermeyi tercih ediyorum
url gönderirseniz api rulelarla uğraşırsınız

http3 denk geldiniz mi? 
günlük yaşamda http1.1 kullanıyorsunuz http2 tüm dünyada yayılmış değil
http3 daha yaygin kullanılacak artık
jwtniz büyükse bu headerlarınz payloaddan daha büyük oluyor
23 fıkrası gibi tüm fıkraları numaralandırmışlar gülüyorlar :D bu tip headerlarda numaralandırıyoruz

sql injection yerine script injection deniyorlar ormler kullanıldıgı için sql injection pek mümkün değil artık, owasplar
developer tool açıksa engellemezler

tasarımlar bitti diyebiliriz.
şimdi OPS kısmındayız
DevOps terimi tanımı çok net değil
nodejs performans ihtiyacı saniyede 3000 request gelecek response zmanı 50 milisaniyeyi geçmeyecek
burada nerede takıldım linux socket açınca 300 milisaniye daha açık kalıyormuş direkt kapatmıyormuş
3000 request açamıyormuşum
linux configürasyon ayarlarından socket timeout süresini 50 milisaniyeye girince sorun çözüldü

DevSecOps,için işine güvenlik denetimleri de girer
GitOps operasyonel süreçlerin yapılma methodolojisidir

farklı ihtiyaçlar için farklı varyasyonlar tanımlanıyor birşey daha ekleniyor. CI/CD pipelan hazırlama yerine DEVOPS süreçlerinizi tasarlamak diyecekler için bir de reklam kısmı var

Configurastion as a Code,  tüm süreçler code olarak yazılmalı ve takip edilmeli
Gitops da tüm süreçleri git üzerinden takip edecel
Jenkins pipelanlarınızın bir git sunucusunda hazırlanması tasarlanması ve Jenkinsin ordan alması gerekiyor

etcKeeper linuxdaki tüm configürasyon dosyalarını etc içinde tutar git gibi etcKeeper da tüm süreçleri buradan takip eder

CI/CD düzenli derleme ve düzenli yükleme mekanızmalarına ihtiyaç var
her defasında manual derlemek ve yüklemek mümkün değil
ister jenkins ister gitlab runner ister tenkton kullanın pipelineların code olarak hazırlanıp takip edilmesi lazım elle bir kere yaparsınız o kağıttan kule yıkılır.

devopsçuların sorumluluğunda bu deployment politikalarını hazırlamak var

Knative gitops da duyarsınız yapılan iş gitteki işi alıp k8se yükler
Knative, serverless workloadların Kubernetes clusterlarında çalışmasını sağlayan ve bulut tabanlı serverless uygulamalarını Kubernetes’e deploy etmek, çalıştırmak ve yönetmek için componentler ekleyen open-source bir frameworktür. 2

SemVer semantic versioning
major minor şöyle yapılır kuralları belli
size her zaman uymuyor olabilir 
1.0.1 gibi bişey yeter da artar deniyor
bazen yetmiyor 
api ve numara sürümünü biryerde takip etmek istiyorum ben derseniz yetmez
1.1.0.1 deyip ikinci kısım api numarasıdır da diyebilirsiniz
redhat tarafı 
javacılar farklı davranıyor 1.1.0.Beta tipinde
özgür yazılım ise sonuncu sürümü de işaretlerler 1.1.0.1- beta rc final ga şeklinde
incremental olmalı, aynı numara iki farklı sürüm için kullanılmaz
tek sayı çift sayı kullanılıyordu bir ara geliştirici sürümü genel kullanım sürümü
pazarlamacılar yeni sürüm çıktı versiyon 2 çıktı şeklinde farklı bir versiyonlama kullanabilirler teknik sürümün bunla alakası yok
cibase veritabanı 4 ten 10a zıplar oracle 10 sürümü oldugu için pazarlama için :D
apache mq server aratınca active mq artemis diye bulacaksınız çünkü kodu baştan yazdılar, pazarlama değildir bu proje adıdır. eski hali devam eder.
marka birleştirilmes sabancı sonuna sa koyar
mal farklılaştırması konusu da var
ürün optimize noktası fiyat ve kişi ortasıdır. bu noktayı buldum
aynı kahve adını değiştirelim daha yüksek fiyat koyalım buna mal farklılaştırması nedir
benzeri yazılım için de geçerli

//öğleden sonra
Sürüm numaraları düzgün verdiniz diyelim nereye koyacaksınız artifact(paket)leri ürününe koymanız gerekecek ve kodunuza ilişkilendirmeniz lazım
o sürüm numarasından kodunuza erişebilmeniz lazım
git link list kullanır çift taraflı yapar
biliyorum ki sürümü git tag bla bla etiketlemem lazım
1.0 1.1
herhangi bir zamanda o sürümü oluşturan kaynak koda geri dönebilmem gerekir, kim yaptı ne zaman yaptı ne değiştirdi
compile ve build ikisine de derleme diyoruz ama burada kastettiğim build

git üzerinde gitflow gitin branch tag commitleri nasıl kullanıcağınıza dair politika akışı belgeniz olması lazım bununda bir üstü gitops zaten
ama ben kişisel olarak daha basit bulduğum için mainline kullanıyorum.
mainden bir feature branch açacaksınız isimlendirme kuralı uygulayın, jira vs bişey kullanıyorsunuz iş bitince maine merge olur
otomasyon kuralı birim testi şu bu bişey yaptım merge request yaptım, gitlab bitbucket github istekte bulununca CI pipeline'ı jenkinsi dürter
üzerinde derlenebiliyor mu statik kod analizi (sonar) vs herşeyi yapar, ben baktım sen bak kısmı code review kısmına geçer, birbaşka kişinin bunu onaylayıp içeri alması gerekir
kurallara uysak da otomatik mekanik oldugu için o süreçler gözden kaçabilir misal sonar Türkçeden anlamıyor isimlendirme İnglizce mi?
ya da algoritma ya da değişken tanımına bakılması lazım, code reviewda reject olabilir kodunuz düzenler tekrar atarsınız ya da merge kabul olur.

ilk gelen merge ile ikinci gelen merge.de conflict varsa,
git rebase komutu ile conflicte baktık ve çözdük
yakın satırlarda bişey varsa çıkıyor ama ya benim methoduma parametre girmişse api kırmışsa, pipeline'nızda bunu da mergeden sonra derlenebiliyor mu diye otomatize edebilirsiniz

mainlineda sürüm kendi başına release branchine gider
sürüm çıkarıtrken önce sürüm adayı çıkacağım politikalarımda bunlar olmalı.
sürüm her zaman cı/cd sisteminden çıkar, birinizin makinesinden çıkmaz !
canlıya çıktım hata var
hata branchleri hatanında tespit edildiği yerden açılır 
release branchine mergeledim hata branchini ve çıktım
mainde henüz bişey yok.
releasedeki hatayı mainde tekrar denemem lazım
cherypick kiraz toplama sadece bu commiti al ve maine getir dedim
bu işi yapabilmek için başka bir şart var conventional atomic commit yapmanız lazım
bir şey mümkünse bir commitle çözülür eğer bir committe birden çok şey yaptıysanız squash yapın sıkıştırın // git merge --squash new-feature
cherrypick ile çözülemezse otur tekrar yaz, o yüzden commitler atomic olmalı bir iş yapmalı
cherrypick ile yapmalısınız iz kalsın
git cherry-pick <commit-hash>
commit logları düzgün yazılmalı
conventional commit yöntemleri var.

feat:Başlık
fix:Başlık
açıklama

<type>[optional scope]: <description>

[optional body]

[optional footer(s)]
refs: #123 // jira numarası redmine numarası yazılır

şu dosyada şunu değiştirdim yazmayın, neden yaptıgınızı yazın
iş takip sisteminde yer alan şeyleri refs kısmına yazmalısınız bu sebeple iştakip numarasını yaz
gitten bişey silemezsiniz son commiti silersiniz ancak revert dediğinizde tersine commit çalıştırır.
fix geçiyor bugfix artırdım, feed geçiyor minor artırdım

şimdi geldik mikroservis versiyonlamasına

satır sonu karakteri utf-8 virgül tab boşluk parantez sonrası nasıl olacak gibi yazım kurallarınız olmalı.
ide formatterı düzgün bir formata göre olmalı, bir kural seti hazırlayıp herkesin idesine bu formatı import edebilirsiniz
Kubernetes YAML Linter for vscode kullanabilirsiniz.

CRLF carriage return line feed and LF line ending on windows/linux
windowsta satır sonu 2 bytetır
carriage return linux enter
macosda blank
//moladan sonra
bağımlılık yönetimi ve sürüm numaraları
npm package.json A ^1.0 yeni sürümü çıktı indiriyor
dışarıda bir de package-lock.json var bunların gite gitmesi gerekiyor
dışarıda lock dosyası varsa bundan sonra o sürümleri kullanacak tekrar silip build almadığım sürece
ya da exact numarası neyse onu yazıyorsunuz çünkü neyin hangi sürümle çalıştıgını bilmek zorundayım.

ben bir paket üretmeliyim ve versiyonları ile birlikte bir artifact deposuna sona type nexusuna misal koymalısınız.
kütüphane lazım olunca herkes ordan alır
kurumun internet deposunda nexusda gider internetten o cachler
indirilen paketin sha1 mda5 ini kiminiz kontrol ediyorsunuz?
içinde başka cryptominer gömmüşler mi
bütün paket sistemleri derleme sırasında elektronic imzalı 
ama kimse uygulamıyor imza atma süreçlerini
nexus indirdiği paketin doğrulugunu test ediyor ve güvenlik açıkları varsa uyarılar da veriyor
o nexus deposunda sizin ürettiğiniz artifactler de duracak
jar war container image'ı hepsini oraya attım kubernete atmak için helm paketi hazırladım onu da oraya attım
kritik olan ne, o depoya kişisel bilgisayardan bişey koymamalısınız
geliştiriciler sadece read only okuma yapmalı o depoya bişey koyma kısmı herkeste olmamalı
derleme cı aracından olmalı
bende çalışıyor problemi
test ortamının çalışması
cı gider son kodu alır gelir.
ama yerel bilgisayardaki derlemenin son kod oldugunun garantisi yok
Türklerden leftpad sola dayama fonksiyonu npm packetini kızmış silmiş, 2016  Azer Koçulu 
tembellik etmeyin kodunu da alın githubta fork almak tek tuş
//mola sonrası
pipelineların bir dosyada durması şart
groovy yml vs dsl domain specific language destekler
bu süreçleri tasarlamanız lazım. kodla aynı depoda olmaz.
jenkins.file, circuit.file sürüm çıkarma deposunda tutuluyor
git deposunda job.dsl vs hepsi duruyor
jenkins makinemi değiştireceğim diyelim hızlıca yapıyorum bu sayede
test jenkins ile pipeline'ı de mikroservis yaparım.
git / gitlab plugin/ güvenlik plugini bitti

geliştirici -> git -> mr merge request açtı gitlab ya da bitbucket gidip -> jenkins -> gite dediki clone all mvn clean install -> 
bağımlılıkları nexuxtan al ->derledi ve java war üretti
--> üzerinde birim testleri ve fonksiyonel testleri yaptı
--> jenkins gitti sonar devamında statıc code analizi yaptı --> quality gate way note verdi B aldı diyelim
--> jenkins ürettiğini warı nexusa koydu ya da helm üretti imageı nexusa koydu 
--> kubernetese dedi ki deployment yml ile bana bir pod açıver, image bu dedi 
--> kubernetes gitti nexustan image aldı çalıştırdı
--> gitlab apisini kullanarak merge requeste yorum yazdık deploymentı yaptım aha burada url diye
--> merge requesti review edecek kişi baktı bunlara 
--> iş takip sistemine ekledi
böylece sistem hazır bekliyor
--> instant rocket chat messager team gibi bişey ile haberleştik
--> jenkins burda bekliyor buildi bitirdim kabul ettim ya da redettim, jenkins jobu burada bitiyor
--> jenkins house keeping jobu ilk gün hala silmemişssin diyor ikinci gün siliyor


mr merge request aynı depodaki iki branch arasında
pull request iki depo arasında

maven paralel derleme de yapar, sadece testleri derle de diyebilirsiniz, hatayı buldun baştan derlemek yerine continuous seçeneği de var
ideleriniz conf.larını okuyun yeteneklerini öğrenin arkadaşlar

//13.02.2025 Perşembe
xml bağımlılıklardan etki analizi 
SBOM software bill of material
kamu kurumları olmazsa olmaz dediği için çılgınlık haline geldi
package-lock.json 'daki bütüüün bunları kullandım ile aynı aslında
hazırladığınız helmler imagelar için de var SBOM
ürünün bağımlı olduğu herşey, isimleri, sürümleri
geliştiriciler bile sadece kendi kullandığı şeylerin bağımlılıgını biliyor, dolaylı olanları da var
eğer düzgün bir paket sistemi ile bağımlılıklarınızı tanımladıysanız güvenlikçiler de bunları kolaylıkla açıklıklarına bakabiliyor
daha açıklanmayan zero day açıklıklarını da planlayıp kolayca güncelleyebiliyorsunuz bu sayede
penetration sızma testleri sırasında farkediliyor ki bu açıklıklar productionda kapatılmamış, çözülemezse CPU açıklıgında oldugu gibi herkese yayınlanıyor
SBOMlar package.json gibi araçlardan tarıyor ve açıklıkları gösteriyor
Nexusun enterprise sürümü de aynı şeyi yapar
fourtyfive da sonar da yazdığıgınız kodun güvenlik açıklıklarını gösteriyor


jboss4 10 yıl once redhatin desteğini sundugu bir sunucuyu kullanıyor bir banka açığı kapatmak için baştan yazıyorlar, 1.5 yıla yazacaklar. orda da redhatin kaynak kodları açık oldugu için redhati yamadık. 

whiteflate hem javaEE hem jakartayı destekledi 5 yıl boyunca. javaEE'yi jakartaya geçirmemişler penetration teslerinde açıklıklar çıktı. Yeniden yazmaya kadar vardı iş.
çalışıyorsa dokunma dışında bu açıklıkların giderilmesi lazım.
bir uygulamanın ömrü 6-8 yıl arası

e-imza implementasyonu için 2 ay üzerinde farklı ister oldu 2 aydaha verdik bitti 3 yıl sonra yeniden beni buldular. yaptık bitti. 2 yıl sonra tekrar geldiler:D
java appletler kullanılıyor java 8 de bile applet yok. tarayıcılar bile desteklemiyor. applet derlemek için ortamı hazırlamak bile çok sürdü. geliştirme ortamını kurmak bile çok problemli oldu. bunun yerine bazen baştan yazmanız bile daha iyi olabilir. bir sürüm geriden gelinir ama on sürüm geriden gelinmez.

image güvenliği de önemli alphine os içine image içine ne gömer acaba docker hub.dan aldıklarınızın da güvenliği önemli artık
kullanmadığınız hiç bir servis o sistemin içinde yer almamalı.

-npm kütüphanesi içinde bilmediğimi crypto paketler vardı için miner paketleri gömmüşler eğer diskinizde cüzdanınız varsa npm install dediğinizde bitmişti, zombi bilgisayar sayısının haddi hesabı yok 

tekir bilgisayar hata ve düzeltmesini yayınladık ama hala hata olduguna dair dönütler alıyorduk meğer indircom gibi biryerden indiriyorlarmış içine herşey gömebilirler

apache sitesinden paket indirieceksiniz en basitinden paket linki md5 sha1 bilgisini yazıyor altına eşit olup olmadıgına bakmanız gerekiyor
paket imzalarını kontrol etmek gerekiyor

e imza nasıl çalışır indiridğiniz sertifika ile anahtarınız kontrol ediliyor sertifika geçerliğini onaylıyorsa tamam
public key 
private key 
birşeyi private key anahtarı ile cryptoladı isem public key ile açabilirim sadece, işin matematiği asal sayıları kullanıyor kocaman kocaman asal sayılar
private key'i güvende tutmalı ve kimse ile paylaşmamalısınız
e-imza sırasında size usb verirler içinde smartkey vardır
private kimseye vermeyim public keyi dağıtacaksınız
e-posta sistemlerinde kullanmamız farz oldu artık, PGP GPG (GNU privacy guard) , benim epostayı göndereceğim kişide benim public anahtarım var karşı tarafın anahtarı ile cryptoluyorum.

TurkTrust komu kurumuna kök sertifika vermiş bunlar da googleın sertifalarını taklit etmiş google tarayıcı sebebiyle bunları sobeledi.
bu sebeple cafe otel wifi vs kullanmayın

ISP konusu suyun başında oturup irlandada veri geçişini dinleyen birileri var, Türkiyede üç tane vardı biri koptu internet de yavaşladı.
sizin ISP'niz size verdiği ip karşılıgında dinlemek zorunda
http protokolünde açık şekilde veri
telnet tüm protokol humanreadable zaten
SSL ile handshake oldugunda ipler görülse bile içindeki veri görünmez
md5ler hızlı ama güvensiz kırması mümkün
GPUlar geliştikçe crypto algoritmalarının çoğu güvensiz artık
sha1 sha5 bunların algoritması aynı sadece bit sayısı farklı
ssl 512den 1024e çıkacak artık
geçtiğimiz yılda opensslde 25 yıldır varolan açık bulundu, hemen kapattılar güncelleyenler güncelledi
XKCD karikatür sitesi var :D
curl kütüphanesi var abi tek başına yazıyor, Daniel Stenberg, http2 http3 protokollerini yazan kişide iyi lakin internetteki herşey tek bir kişinin yazdıgı curl üzerinde duruyor

//mola sonrası 5 dk geçikme
UAT (kullanıcı kabul testi) ortamı preprod.da otomatik deployment yapacagınız kısım burası
canlı ve preprod arasında ortam farkı olabilir ancak bu configürasyonla yapılabilir olması yeniden derlenmemeli aynı binary gitmeli.
yeni kodlarla yeni hatalar mutlaka gelir o yüzden preprodda test ettiğiniz şeyi canlıya koymalısınız.
dbler arasında data farkı olur ama schema farkı olmamalı.
birim testi üstüne test seneryosu ile fonksiyonel test de yapılmalı, 
apiler üzerinde http request json çıktısı derken postmande bu kolay
bir adım sonrası entegrasyon sistemidir, otomatize edilmesi her zaman mümkün olmayabiliyor,size verilen saop test apisi düşünün e-reçete sisteminizi o apiyi kullanarak test edeceksiniz diyelim test ortamı eskide kaldı ya da kapalı.
en basitinden selenium testlerinizin olması bile bir adım
canlıda yapılabilecek test, yük testidir.
test yazmak da değil özellikle temporal data varsa, uçak kalkış saati yaklaştıkça bilet fiyatı değişir, buna uygun kod yazmak hayli yorucu oldu.
factory girl random test datası üretmek için kullanılan bir kütüphane
test ortamınızı dinamic bir şekilde çalıştırmak için TestContainers var, kullanın. Junit vs diğer dillerle entegrasyonu var bunun.
alternative kubernetes tarafında bir pod kaldır işim bitince kapat.
yazdığınız kodu test edilebilir şekilde yazmalı parçamalısınız.
karmaşıklık oranı cyclomatic complexity oranı diye birşey var. fonksiyon seviyesinde birim karmaşıklığını ölçmek için kullanılır.
if end oranı 4ü geçiyorsa cyclomatic complexity oranı  artar bir daha bakın kodunuza.
teknik borç (tecnical dept) diye bir metaphor var, kodu düzeltmediğiniz sürece borcunuz artar

:preproda en güncel hali mi yükledik? hayır release branchten çıktınız versiyona diyelim yeni özellikleri eklemediniz main branchte en güncel hali.

TDD test driven development
BDD behaviour driven development

ruby function call yapmaz message sent yapar? TDD yapmanızı öneririm önce testi yazıp sonra kodu yazıp bunu geçmesini bekliyorsunuz, maliyet zaman problemli yapabilir tabi test senaryonuzun doğru sayıldıgı iyi ihtimalle
en basit toplama senaryosu 7-8 tane birim test kodu var, doğru sonuç hatalı sonuç derken test yazma maliyeti yüksek

BDD sistem analizi yaparken usecase yazın cucumber kütüphanesi Gherkin dili automated acceptance test tool

Deploymentta ortaya çıkan bir sorun productiondaki ve test için kullanılan ortamlarda donanımsal farklar da var
bu farklar nedeniyle de sorun çıkabiliyor
uygulamanızın ihtiyaç duyduğu kaynaklarda ram cpu threadpoolum ne kadar olacak gibi ayarlar preprod ve canlıda fark eder tüm bunları environments variable.dan almalı, external dışarıdan alınması kodun içine gömmemesi gerekiyor. sample uzantısı ile gite gönderebilirsiniz.
kubernetes ortamında mikroservis mantıgında söylüyorum mümkünse merkezi conf aracı seçin spring cloud config server, zookeeper, consul HashiCorp, kubernetes configmap gibi yerlerde tutulması lazım konfigürasyonların.

configmap secretmap var kuberneteste bu credentialların saklandığı o yüzden cı içinde olmamalı.
keepass gibi uygulamalar kullanabilirsiniz telefonunuzda password txt diye açık açık yazmayınız
aws key githuba atmışlar beş dakika sürmez almaları on bin dolarlık fatura gelebilir, geri düzeltmişler ama her zaman bu kadar şanslı olmazsınız.

:configmap test için configmap içn ne yapmalı?
ben gitte branch açıyorum test production vs
yml içinden de bunu yapabilirsiniz

git; linklist yapısında her commit kendi parentının IDsini taşıyor, dolayısıyla gitte commit silemezsiniz.
Son node son committeki şeyde değişiklik yapabilirsiniz, yerel git reposunda yapabilirsiniz
revert tersine commit atıyor
id,committer, author
|
diff/patch
|

paralo vs attıgınızda silinmez.
commitin hashını binarysini sha5ini vs yapmak gibi en zor haliyle mümkün legacy yöntem var

git kullanmak kritik hale gelmiş durumda, localde de iki farklı remote yaparak çalışabilirsiniz. varlıgından haberiniz olmayan şey yoktur.
var oldugunu bilseniz gerisini arar dener uygularsınız
git için faydalı bir site; 
https://learningitbbranching.js.org


rfc request for comment // şuna bakın bir yorumlasanıza demek
internet mail extencions (mime) typeın rfc konusunu araştır.

bu git işleri kubernetes.te nasıl yapılır gitops ile
kubernetesin kendi verdiği api var, bu yetenekleri kullanarak yapılan uygulamalara knative denir.
rest api davranışı nasıl
get ıd verirseninz bir nesne alırsınız
get query 
post create
put update
delete delete işlemi şeklinde bir seri api var, bunun arkasında da kubernetes nesnelerimiz var
bu nesleri kullanarak, postman aracı vs ile siz de bu api çağrılarını kullanarak kendiniz de yazabilirsiniz.

kuberneteste çok düzgün tanımlanmış model ve controller var.
POST /deploy apisine json post ediyorum controller bu modeldeki bilgiyi okuyor ve ne yapacaksa yapıyor.
kubernetes controller vs gibi hazır nesneleri kendimiz de implement edebiliyoruz custom resource definition (CRD) deniyor buna.

apache camel'ın knative yapısı var Kamelets - Apache Camel
kuberneteste buna operator deniyor. openshift bu operator patternini çok kullanır. 
tekton diye doğrudan kubernetese gömülmüş bir cı/cd aracı var tüm süreci siz de custom resource oluşturup kubernetese koyup traffic rulelarını bazıp knative yapabilirsiniz şuanki bazı apigatewayler böyle çalışıyor

test için ayrı kubernetes clusterları kurmaya ihtiyacınız var.
openshift router üzerine bişey kurduysanız onu alıp rancherde koşamazsınız artık openshifte bağımlı hale geldiniz demektir.
geçtiğimiz yıllarda kubernetes çok sık api kırıyordu. artık experimentalları önceden söylüyor değişecek depricate oldu o apiyi kullanma biçiminizi değiştirin diyor

operator patterni ile bişey kurmaya o yüzden helm'i tercih ediyorum, paket sistemi, npm maven nuget yönetebildiğimiz gibi helm de yönetiyoruz ama yaml dosyalarını yönetemiyoruz, git gitops kullanabilirsiniz.

git -> jenkins -> k8s
jenkins içindeki seed job var bu güncellenince çalış diyorsunuz kendi içindeki joblistleri tetikliyor

mono repo yapın ya da dağıtın
eğer ki kuralları başta koymazsanız dağılır, sürdürülebilirlik ve bakım zorlaşır.

IT dünyasında random iş yapmak zordur ve birşeye isim vermek zordur, sınıfa, değişkene, ürüne..
isimlendirme kuralı ile yola çıkmanız gerek
meyve ismi , balık ismi kullandık saçma olması önemli değil uniqe isim verirken düşünmüyorlar sunucuya s001den daha anlamlı
log in to SonarQube adımız https://davut.ozguryazilim.com.tr

PKCS-11
PKCS-12 arasında benzerlik yok 12 public key saklama deposu diğeri o public keylerin hede standartının deposu
fonksiyonalite de olabilir isim seçiminde payment ödeme vs 

İzleme Monitoring araçlarınızı kurmak ve bağlamak da bu otomasyonun parçası
işletim sistemi yazılım donanımlarınızı izleyeceksiniz mikroservisle cı/cd'ye geçirince düzenli izleme continuous monitoring deniyor bunun da yüklerken hepsini izleyecek şekilde ayarlanması gerekiyor, sorun izlemediğiniz sistemde çıkmasın sonra :D

merkezi log tutma sistemlerinize otomatik log tutma yapmanız lazım

openshift bundle prometheus ile beraber gelir
rancher helm prometheus grafana kurarım bağlarım diyebilirsiniz.
bütün herşeyi izleme maliyeti çok olacagı için bazen örnek küme replica seçilir ama genelde sorun izlenmeyen üzerinden çıkar
yine de hiç izlememektense bir kısmını izleyin
spring opentracing ile destekli gelir siz bir http client çağrısı yapınca prometheusa gönderir servlet çağrısı yapınca dinler gönderir otomatik yapar
tüm loglama sistemlerinin bir de housekeepinge ihtyacı var ne kadar saklayacağız, ne kadar saklamaya izin var ya da boyut ne kadar izin veriyor buna göre birşey çıkarmalısınız

bilet satımında 1 yıllık request responseları saklıyor davalar olabiliyor,,
sadece bir gün tutmanızın hiç anlamı yok hiç tutmayın, anomali tespit ederken geçmiş veriye ihtiyacım var geçen haftayı oturup inceleyeceğim vs
erişim güvenliği nerede nasıl saklanacak gibi sorunlar da var, maskeleme yapmanız gerekebilir, 










